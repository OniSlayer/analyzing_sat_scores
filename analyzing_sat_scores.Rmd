---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.3
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Analyzing sat scores

This proyect is about analyzing sat scores and how they correlate to other factors like the size of the school, ethnicity or percentage of native english speakers


## Preliminaries

```{python}
# !ls data
```

```{python}
# Reading the data files and importing necessary libraries.
import pandas as pd
import numpy
import re

data_files = [
    "ap_2010.csv",
    "class_size.csv",
    "demographics.csv",
    "graduation.csv",
    "hs_directory.csv",
    "sat_results.csv"
]

data = {}

for f in data_files:
    d = pd.read_csv("data/{0}".format(f))
    data[f.replace(".csv", "")] = d
```

```{python}
# Reading text files 

all_survey = pd.read_csv("data/survey_all.txt", delimiter="\t", encoding='windows-1252')
d75_survey = pd.read_csv("data/survey_d75.txt", delimiter="\t", encoding='windows-1252')
survey = pd.concat([all_survey, d75_survey], axis=0)

survey["DBN"] = survey["dbn"]

survey_fields = [
    "DBN", 
    "rr_s", 
    "rr_t", 
    "rr_p", 
    "N_s", 
    "N_t", 
    "N_p", 
    "saf_p_11", 
    "com_p_11", 
    "eng_p_11", 
    "aca_p_11", 
    "saf_t_11", 
    "com_t_11", 
    "eng_t_11", 
    "aca_t_11", 
    "saf_s_11", 
    "com_s_11", 
    "eng_s_11", 
    "aca_s_11", 
    "saf_tot_11", 
    "com_tot_11", 
    "eng_tot_11", 
    "aca_tot_11",
]
survey = survey.loc[:,survey_fields]
data["survey"] = survey

```

```{python}
# Creating the DBN columns for the class_size data set and lowercasing the name on the hs_directory

data["hs_directory"]["DBN"] = data["hs_directory"]["dbn"]

def pad_csd(num):
    string_representation = str(num)
    if len(string_representation) > 1:
        return string_representation
    else:
        return "0" + string_representation
    
data["class_size"]["padded_csd"] = data["class_size"]["CSD"].apply(pad_csd)
data["class_size"]["DBN"] = data["class_size"]["padded_csd"] + data["class_size"]["SCHOOL CODE"]
```

```{python}
# Converting values stored as text to number

cols = ['SAT Math Avg. Score', 'SAT Critical Reading Avg. Score', 'SAT Writing Avg. Score']
for c in cols:
    data["sat_results"][c] = pd.to_numeric(data["sat_results"][c], errors="coerce")

data['sat_results']['sat_score'] = data['sat_results'][cols[0]] + data['sat_results'][cols[1]] + data['sat_results'][cols[2]]

```

```{python}
# Extracting longitude and latitude and converting the data to numbers

def find_lat(loc):
    coords = re.findall("\(.+, .+\)", loc)
    lat = coords[0].split(",")[0].replace("(", "")
    return lat

def find_lon(loc):
    coords = re.findall("\(.+, .+\)", loc)
    lon = coords[0].split(",")[1].replace(")", "").strip()
    return lon

data["hs_directory"]["lat"] = data["hs_directory"]["Location 1"].apply(find_lat)
data["hs_directory"]["lon"] = data["hs_directory"]["Location 1"].apply(find_lon)

data["hs_directory"]["lat"] = pd.to_numeric(data["hs_directory"]["lat"], errors="coerce")
data["hs_directory"]["lon"] = pd.to_numeric(data["hs_directory"]["lon"], errors="coerce")
```

```{python}
# Selecting only nine graders from 2012 generations

class_size = data["class_size"]
class_size = class_size[class_size["GRADE "] == "09-12"]
class_size = class_size[class_size["PROGRAM TYPE"] == "GEN ED"]

class_size = class_size.groupby("DBN").agg(numpy.mean)
class_size.reset_index(inplace=True)
data["class_size"] = class_size

data["demographics"] = data["demographics"][data["demographics"]["schoolyear"] == 20112012]

data["graduation"] = data["graduation"][data["graduation"]["Cohort"] == "2006"]
data["graduation"] = data["graduation"][data["graduation"]["Demographic"] == "Total Cohort"]
```

```{python}
# Converting text values to numeric

cols = ['AP Test Takers ', 'Total Exams Taken', 'Number of Exams with scores 3 4 or 5']

for col in cols:
    data["ap_2010"][col] = pd.to_numeric(data["ap_2010"][col], errors="coerce")
```

```{python}
# Merging the datasets

combined = data["sat_results"]

combined = combined.merge(data["ap_2010"], on="DBN", how="left")
combined = combined.merge(data["graduation"], on="DBN", how="left")

to_merge = ["class_size", "demographics", "survey", "hs_directory"]

for m in to_merge:
    combined = combined.merge(data[m], on="DBN", how="inner")

combined = combined.fillna(combined.mean())
combined = combined.fillna(0)
```

```{python}
# Generating the district column on the combined dataset
def get_first_two_chars(dbn):
    return dbn[0:2]

combined["school_dist"] = combined["DBN"].apply(get_first_two_chars)
```

```{python}
# Printin existing coorelations with the sat_score

correlations = combined.corr()
correlations = correlations["sat_score"]
print(correlations.sort_values())
```

```{python}
# Plotting correlations between sat_score and the survey_fields columns

correlations[survey_fields].plot.bar()
```

```{python}
# There is a strong correlation between saf_t_11 and the sat_score, and also between saf_s_11 and the sat score.
# This set a relation between a safe school and the score of the sat. 

# Looking deeper into the possible relation, a scatter plot between the saf_s_11 and sat_score is made

combined.plot.scatter(x = 'saf_s_11', y = 'sat_score')

# There seems to be a possitive correlation betwwen the saf_s_11 and the sat_score
```

```{python}
# Grouping the whole dataset by district and computing the mean of each of the columns

group_district = combined.groupby('school_dist')
average_safety_by_district = group_district.mean()
average_safety_by_district.reset_index(inplace = True)
```

```{python}
# A central spot in new york can be observed to have lower safety perception by the students

import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap

districts = combined.groupby("school_dist").agg(numpy.mean)
districts.reset_index(inplace=True)

m = Basemap(
    projection='merc', 
    llcrnrlat=40.496044, 
    urcrnrlat=40.915256, 
    llcrnrlon=-74.255735, 
    urcrnrlon=-73.700272,
    resolution='i'
)

m.drawmapboundary(fill_color='#85A6D9')
m.drawcoastlines(color='#6D5F47', linewidth=.4)
m.drawrivers(color='#6D5F47', linewidth=.4)
m.fillcontinents(color='white',lake_color='#85A6D9')

longitudes = average_safety_by_district['lon'].tolist()
latitudes = average_safety_by_district['lat'].tolist()
m.scatter(longitudes, latitudes, s=50, zorder=2, latlon=True, c=average_safety_by_district["saf_s_11"], cmap="summer")
plt.show()
```

```{python}
# Race migth also be related to the SAT scores
# There are 4 columns that contains the percentage of each race that a school has. 
# The correlation bewteen the sat scores and each of this percentages is analyzed. 

# There seems to be a positive and significative correlation between the white and asian percentage
# and a negativa correlation between black and hispanic.
combined.corr()['sat_score'][['white_per', 'asian_per', 'black_per', 'hispanic_per']].plot.bar()

```

```{python}
# Inspecting the hispanic correlation more closely

# This plot shows a clear negative correlation between sat_score and the percentage of hispanics
combined.plot.scatter(x = 'hispanic_per', y = 'sat_score')
```

```{python}
# Analyzing those schools with a high percentage of hispanic 

schools_high_hispanics = combined[combined['hispanic_per']> 95]
print(schools_high_hispanics['SCHOOL NAME'])
```

```{python}
# Analyzing schools with high average sat score and low percentage of hispanics

combined[(combined['hispanic_per'] < 10) & (combined['sat_score']>1800)]['SCHOOL NAME']
```

```{python}
# There are two columns showing the average of women and men on each school
# The correlation between gender and the sat score is plotted below

# There seems to be a positive relation of the score and the number of females
# There is a negative relation between the percentage of males and the sat score
combined.corr()['sat_score'][['female_per', 'male_per']].plot.bar()
```

```{python}
# Ploting female percentage and sat scores

# There is no clear correlation between the female percentage and the sat score. 

# Most of schools with a high sat score have between 40 to 60 percent of women
combined.plot.scatter(x = 'female_per', y = 'sat_score')
```

```{python}
# Analyzing schools with more than 1700 points on the sat and more than a 60% of female population

# All of this schools have admissions exams and are related to ars

combined[(combined['female_per']>60) & (combined['sat_score']>1700)]['SCHOOL NAME']
```

```{python}
# Analyzing Advance Placement exams and sat scores

# Calculating the percentage of AP test takers in each school
combined['ap_per'] = combined['AP Test Takers '] / combined['total_enrollment']
```

```{python}
# Plotting the percentage of AP test takers vs the sat score

# There seems to be a postive relation, but is not very strong
combined.plot.scatter(x = 'ap_per', y = 'sat_score')
```

```{python}

```
